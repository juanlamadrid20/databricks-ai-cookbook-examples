{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0ede9ee-6a85-4142-ac9c-dfcb8308a088",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9bd053b-bc57-4b3d-baf8-ffda6adf93fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db307b1f-6244-4a23-97e2-530ad9362ae9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.models import ModelConfig\n",
    "\n",
    "mlflow.langchain.autolog()\n",
    "config = ModelConfig(development_config=\"config.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68126a4c-1f3b-4c90-85a2-8e0a258d057b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_databricks import ChatDatabricks\n",
    "\n",
    "# Create the llm\n",
    "llm = ChatDatabricks(endpoint=config.get(\"llm_endpoint\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce8f0265-9c8f-4985-996d-e1b684757f62",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def clean_string(input_string: str) -> str:\n",
    "    cleaned = re.sub(r'[^a-zA-Z0-9\\s]', '_', input_string)\n",
    "    cleaned = re.sub(r'\\s+', '_', cleaned)\n",
    "    cleaned = re.sub(r'_+', '_', cleaned)\n",
    "    return cleaned.strip('_')\n",
    "\n",
    "\n",
    "genie_space_id = config.get(\"genie_space_id\")\n",
    "_genie_agent_name = config.get(\"genie_agent_name\")\n",
    "genie_space_description = config.get(\"genie_space_description\")\n",
    "\n",
    "assert genie_space_id, f\"Configure the genie_space_id in config.yml it is: {genie_space_id}\"\n",
    "assert _genie_agent_name, f\"Configure the genie_agent_name in config.yml it is: {_genie_agent_name}\"\n",
    "assert genie_space_id, f\"Configure the genie_space_description in config.yml it is: {genie_space_description}\"\n",
    "\n",
    "genie_agent_name = clean_string(_genie_agent_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d2b6635-16b5-4eab-9a09-fcf3c5243562",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.tools import BaseTool, StructuredTool, tool\n",
    "from langchain_core.callbacks.manager import CallbackManagerForToolRun\n",
    "from databricks_langchain.genie import GenieAgent\n",
    "from pydantic import BaseModel, Field\n",
    "import typing as t\n",
    "import re\n",
    "\n",
    "class GenieAgentInput(BaseModel):\n",
    "    question: str = Field(description=\"question to ask the agent\")\n",
    "    summarized_chat_history: str = Field(description=\"summarized chat history to provide the agent context of what may have been talked about. Say 'No history' if there is no history to provide.\")\n",
    "\n",
    "\n",
    "genie_agent = GenieAgent(\n",
    "    genie_space_id, \n",
    "    config.get(\"genie_agent_name\"), \n",
    "    description=genie_space_description)\n",
    "\n",
    "\n",
    "class GenieQuestionTool(BaseTool):\n",
    "    name = genie_agent_name\n",
    "    description = genie_space_description\n",
    "    args_schema: t.Type[BaseModel] = GenieAgentInput\n",
    "\n",
    "    def _run(\n",
    "        self, question: str, summarized_chat_history: str, run_manager: t.Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        return genie_agent.invoke({\n",
    "            \"messages\": [\n",
    "                {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"ChatHistory: {summarized_chat_history}\\nQuestion: {question}\"\n",
    "                }\n",
    "            ]\n",
    "        })\n",
    "\n",
    "\n",
    "tools = [GenieQuestionTool()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc0c5e92-cd9b-4db3-a6db-4045670754ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "# Get the prompt to use - can be replaced with any prompt that includes variables \"agent_scratchpad\" and \"input\"!\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "prompt.pretty_print()\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0320897b-e00c-478d-9c34-dd986bb16603",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85cc3604-9c1d-4c4a-97b9-84792d699b49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.langchain.output_parsers import ChatCompletionsOutputParser\n",
    "\n",
    "output_parser = ChatCompletionsOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf450e42-9dd3-4858-9c11-aa0605874c91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# needed because agent executor returns {\"input\": \"...\", \"output\": \"...\"}\n",
    "def agent_executor_to_just_response(inp):\n",
    "    return inp[\"output\"]\n",
    "  \n",
    "def pre_process_input(inp):\n",
    "    # this is needed to conform to agent executor input which requires input and agent_scratchpad\n",
    "    return {\n",
    "        \"input\": inp\n",
    "    }\n",
    "\n",
    "chain = RunnableLambda(pre_process_input) | agent_executor | RunnableLambda(agent_executor_to_just_response) | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a97a6c27-b607-4e43-952c-6568bdc8e538",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# chain.invoke(\"Which platforms have the highest number of churned users based on the last event before churning?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8954be9c-ea4d-42d2-b291-d7e12e6e231d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.models.set_model(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a155f8df-42bf-45e6-a1ff-ba5a476b1a1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "model",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}