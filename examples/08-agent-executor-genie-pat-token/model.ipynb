{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a04adcf-4f71-4b8a-b7f2-3ceab0621f28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2486c106-1109-4bc8-8bdf-0dc8b18c1752",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c5dee6b2-c59c-401b-9bfc-f8e6f47cee70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.models import ModelConfig\n",
    "\n",
    "mlflow.langchain.autolog()\n",
    "config = ModelConfig(development_config=\"config.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "387b4c0a-526b-43ae-b43f-44ea7ae69cb1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_databricks import ChatDatabricks\n",
    "\n",
    "# Create the llm\n",
    "llm = ChatDatabricks(endpoint=config.get(\"llm_endpoint\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "16017ea7-fbf5-4886-a50d-b0e5ab2eb30f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_string(input_string: str) -> str:\n",
    "    cleaned = re.sub(r'[^a-zA-Z0-9\\s]', '_', input_string)\n",
    "    cleaned = re.sub(r'\\s+', '_', cleaned)\n",
    "    cleaned = re.sub(r'_+', '_', cleaned)\n",
    "    return cleaned.strip('_').lower()\n",
    "\n",
    "\n",
    "genie_space_id = config.get(\"genie_space_id\")\n",
    "_genie_agent_name = config.get(\"genie_agent_name\")\n",
    "genie_space_description = config.get(\"genie_space_description\")\n",
    "\n",
    "assert genie_space_id, f\"Configure the genie_space_id in config.yml it is: {genie_space_id}\"\n",
    "assert _genie_agent_name, f\"Configure the genie_agent_name in config.yml it is: {_genie_agent_name}\"\n",
    "assert genie_space_id, f\"Configure the genie_space_description in config.yml it is: {genie_space_description}\"\n",
    "\n",
    "genie_agent_name = clean_string(_genie_agent_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cfbb6c87-05fd-44ff-8a8b-3427bfa1ead5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.tools import BaseTool, StructuredTool, tool\n",
    "from langchain_core.callbacks.manager import CallbackManagerForToolRun\n",
    "from databricks_langchain.genie import GenieAgent\n",
    "from pydantic import BaseModel, Field\n",
    "import typing as t\n",
    "\n",
    "class GenieAgentInput(BaseModel):\n",
    "    question: str = Field(description=\"question to ask the agent\")\n",
    "    summarized_chat_history: str = Field(description=\"summarized chat history to provide the agent context of what may have been talked about. Say 'No history' if there is no history to provide.\")\n",
    "\n",
    "\n",
    "genie_agent = GenieAgent(\n",
    "    genie_space_id, \n",
    "    config.get(\"genie_agent_name\"), \n",
    "    description=genie_space_description)\n",
    "\n",
    "\n",
    "class GenieQuestionTool(BaseTool):\n",
    "    name = genie_agent_name\n",
    "    description = genie_space_description\n",
    "    args_schema: t.Type[BaseModel] = GenieAgentInput\n",
    "\n",
    "    def _run(\n",
    "        self, question: str, summarized_chat_history: str, run_manager: t.Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        return genie_agent.invoke({\n",
    "            \"messages\": [\n",
    "                {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"ChatHistory: {summarized_chat_history}\\nQuestion: {question}\"\n",
    "                }\n",
    "            ]\n",
    "        })\n",
    "\n",
    "\n",
    "tools = [GenieQuestionTool()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4786dabe-fe83-4968-a784-69aef8d0aae3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "# Get the prompt to use - can be replaced with any prompt that includes variables \"agent_scratchpad\" and \"input\"!\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "prompt.pretty_print()\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "31af3e3f-c18b-456f-9258-d6695537b58c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9fd94434-7f1c-4fe3-92fd-04e678f71d8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.langchain.output_parsers import ChatCompletionsOutputParser\n",
    "\n",
    "output_parser = ChatCompletionsOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d83a96e7-b285-4f8f-982f-750750e6d14e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# needed because agent executor returns {\"input\": \"...\", \"output\": \"...\"}\n",
    "def agent_executor_to_just_response(inp):\n",
    "    return inp[\"output\"]\n",
    "  \n",
    "def pre_process_input(inp):\n",
    "    # this is needed to conform to agent executor input which requires input and agent_scratchpad\n",
    "    return {\n",
    "        \"input\": inp\n",
    "    }\n",
    "\n",
    "chain = RunnableLambda(pre_process_input) | agent_executor | RunnableLambda(agent_executor_to_just_response) | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3c0e6bd4-230f-4215-baa7-414a68a17ef6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# chain.invoke(\"Which platforms have the highest number of churned users based on the last event before churning?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bee5c792-8500-4ddd-83c3-59f653b64b83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.models.set_model(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dd1f7363-c9d7-41fb-9fca-10b4b34a0560",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "model",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
